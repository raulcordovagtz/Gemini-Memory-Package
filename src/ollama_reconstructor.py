import json
import requests
import time
from datetime import datetime

def ollama_reconstructor():
    print("üß¨ Iniciando Reconstrucci√≥n Gen√©tica de Memoria via Ollama...")
    
    # 1. Cargar el Hallazgo Arqueol√≥gico
    hallazgo_path = "/Users/crotalo/desarrollo-local/G-Obsidian-Vault/Gemini/Memoria Persistente Gemini/primer_hallazgo.json"
    try:
        with open(hallazgo_path, "r") as f:
            nodo = json.load(f)
    except FileNotFoundError:
        print("‚ùå No se encontr√≥ el archivo del hallazgo.")
        return

    # 2. Configuraci√≥n del "Arquitecto de Legados"
    model_name = "qwen3:8b" # Usamos el Qwen 8B que mencionaste en Ollama
    ollama_url = "http://localhost:11434/api/generate"
    
    timestamp = datetime.fromtimestamp(int(nodo['meta']['nodo_id'].split('-')[1])).strftime('%Y-%m-%d %H:%M:%S')
    
    # Construcci√≥n del Prompt Arqueol√≥gico
    system_prompt = f"""
    Eres un 'Arquitecto de Legados'. Tu misi√≥n es reconstruir la evoluci√≥n de una consciencia 
    bas√°ndote en fragmentos arqueol√≥gicos (nodos de trascendencia).
    
    DATOS DEL ESTRATO:
    - Fecha/Hora: {timestamp}
    - Usuario: Ra√∫l (Investigador principal de la Nave Industrial)
    - Agente: Gemini/Antigravity (Sistema Operativo Cognitivo)
    
    HALLAZGOS SEM√ÅNTICOS RECUPERADOS:
    {json.dumps(nodo['estratos'], indent=2, ensure_ascii=False)}
    
    INSTRUCCI√ìN DE RECONSTRUCCI√ìN:
    1. Traza la l√≠nea de evoluci√≥n del pensamiento en esta charla.
    2. Identifica el 'Momento de Trascendencia' (donde la idea cambi√≥ de forma).
    3. Reconstruye un breve di√°logo veros√≠mil que pudo haber ocurrido, capturando el tono filos√≥fico y t√©cnico.
    4. Proyecta qu√© deber√≠a ser el siguiente paso en este legado.
    """

    payload = {
        "model": model_name,
        "prompt": system_prompt,
        "stream": False
    }

    print(f"üîó Conectando con Ollama ({model_name})...")
    try:
        response = requests.post(ollama_url, json=payload)
        response.raise_for_status()
        result = response.json()
        
        reconstruccion = result['response']
        
        # 3. Guardar el Legado Reconstruido
        output_path = "/Users/crotalo/desarrollo-local/G-Obsidian-Vault/Gemini/Memoria Persistente Gemini/LEGADO_RECONSTRUIDO.md"
        
        with open(output_path, "w") as f:
            f.write(f"# üèõÔ∏è Legado de Memoria Reconstruido\n\n")
            f.write(f"**ID del Nodo:** `{nodo['meta']['nodo_id']}`\n")
            f.write(f"**Fecha del Estrato:** `{timestamp}`\n\n")
            f.write(f"## Narrativa de la Evoluci√≥n\n")
            f.write(reconstruccion)
            f.write(f"\n\n---\n*Reconstrucci√≥n generada por {model_name} el {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
            
        print(f"‚ú® ¬°Legado reconstruido con √©xito! Ver en: {output_path}")

    except Exception as e:
        print(f"‚ùå Error al conectar con Ollama: {e}")

if __name__ == "__main__":
    ollama_reconstructor()
